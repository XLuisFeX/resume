{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 28s 583us/sample - loss: 0.3908 - accuracy: 0.8835 - val_loss: 0.1080 - val_accuracy: 0.9697\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 27s 569us/sample - loss: 0.1240 - accuracy: 0.9627 - val_loss: 0.0733 - val_accuracy: 0.9806\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 27s 564us/sample - loss: 0.0913 - accuracy: 0.9711 - val_loss: 0.0591 - val_accuracy: 0.9826\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 27s 561us/sample - loss: 0.0772 - accuracy: 0.9762 - val_loss: 0.0524 - val_accuracy: 0.9847\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 29s 594us/sample - loss: 0.0664 - accuracy: 0.9783 - val_loss: 0.0520 - val_accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fad2896a690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.03909132170961238\n",
      "Test accuracy: 0.9873\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_img = 54\n",
    "img = x_test[index_img][:,:,0]\n",
    "print(img.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction for test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class of the input image is: 6\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes(x_test[index_img:index_img+1])[0]\n",
    "print('The class of the input image is: ' + str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
